{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "546e6756",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0f64ddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-02 20:40:36.684972: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from fobokiller.heatmap import load_reviews_dataset, heatmap_sentences, \\\n",
    "load_model,apply_heatmap_html,apply_heatmap_polarity\n",
    "\n",
    "from fastapi import FastAPI, Query\n",
    "from fastapi.middleware.cors import CORSMiddleware\n",
    "import pandas as pd\n",
    "from typing import List\n",
    "\n",
    "from fobokiller.cosim import compute_sim_df, load_embedding, summary_reviews\n",
    "#words/sentences  preprocessing\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras import backend as K\n",
    "#modeling\n",
    "from tensorflow import GradientTape\n",
    "import tensorflow as tf#modeling\n",
    "from tensorflow.keras import models, layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b3411d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "resto_list = pd.read_csv(\"../api/final_resto_list.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03fc19e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "embedding = load_embedding()\n",
    "\n",
    "reviews_dataset = load_reviews_dataset()\n",
    "\n",
    "model_heatmap = load_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e219ca35",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "\n",
    "app.add_middleware(\n",
    "    CORSMiddleware,\n",
    "    allow_origins=[\"*\"],  # Allows all origins\n",
    "    allow_credentials=True,\n",
    "    allow_methods=[\"*\"],  # Allows all methods\n",
    "    allow_headers=[\"*\"],  # Allows all headers\n",
    ")\n",
    "\n",
    "\n",
    "temp =[]\n",
    "result = []\n",
    "\n",
    "@app.get(\"/\")\n",
    "def index():\n",
    "    return {\"greeting\": \"Hello world\"}\n",
    "\n",
    "\n",
    "#Input list of restaurant (alias)\n",
    "# detail\n",
    "@app.get(\"/detail\")\n",
    "def get_details(alias):\n",
    "\n",
    "    alias = [alias]\n",
    "    pd_liste = resto_list.loc[resto_list['alias'].isin(alias), :]\n",
    "    return pd_liste.to_dict()\n",
    "\n",
    "\n",
    "\n",
    "@app.get(\"/details/\")\n",
    "def read_items(alias: List[str] = Query(None)):\n",
    "    print(alias)\n",
    "    pd_liste = resto_list.loc[resto_list['alias'].isin(alias), :]\n",
    "    print(pd_liste)\n",
    "\n",
    "    return pd_liste.to_dict()\n",
    "\n",
    "@app.get(\"/summary_reviews\")\n",
    "def sr(text, n_best=10, n_prox=3000, min_review=0):\n",
    "    min_review = int(min_review)\n",
    "    print(type(n_prox))\n",
    "    if pd.isna(n_prox):\n",
    "        pass\n",
    "    else:\n",
    "\n",
    "        n_prox = int(n_prox)\n",
    "    temp = compute_sim_df(text, embedding, n_prox, min_review)\n",
    "    n_best = int(n_best)\n",
    "    result = summary_reviews(temp, n_best)\n",
    "    return result.to_dict()\n",
    "\n",
    "\n",
    "\n",
    "@app.get(\"/summary_reviews2\")\n",
    "def sr2(text, n_best=1, n_prox=3000, min_review=10):\n",
    "\n",
    "    #setting types\n",
    "    min_review = int(min_review)\n",
    "    if pd.isna(n_prox):\n",
    "        pass\n",
    "    else:\n",
    "        n_prox = int(n_prox)\n",
    "    n_best = int(n_best)\n",
    "\n",
    "    #loading datasets\n",
    "    results = compute_sim_df(text, embedding, n_prox, min_review)\n",
    "    summary = summary_reviews(results, n_best)\n",
    "    results['is_sim'] = 1\n",
    "    summary['is_in_summary'] = 1\n",
    "    results_trimed = results.drop(\n",
    "        columns=['alias', 'rate', 'review_sentences'])\n",
    "\n",
    "    #merging datasets and house cleaning\n",
    "\n",
    "    tmp_df = reviews_dataset.merge(results_trimed,\n",
    "                                   on='review_clean',\n",
    "                                   how='left')\n",
    "    tmp_df['is_sim'].fillna(0, inplace=True)\n",
    "    all_df = tmp_df.merge(summary, on='alias', how='left')\n",
    "    all_df.fillna(0, inplace=True)\n",
    "    all_df = all_df[all_df[\"is_in_summary\"]==1]\n",
    "\n",
    "    #apply heatmap for html and polarity score\n",
    "    all_df['reviews_heatmaps_html'] = all_df.apply(apply_heatmap_html,axis=1)\n",
    "    all_df['reviews_heatmaps_polarity'] = all_df.apply(apply_heatmap_polarity, axis=1)\n",
    "    ####  metrics for the val of the request\n",
    "    all_df['request_metric'] = all_df[(all_df['is_in_summary'] == 1) & (\n",
    "        all_df['is_sim'] == 1)]['nb_sentences'].sum() *100 /3000\n",
    "    summary_reconstructed = all_df.groupby('alias').agg({\n",
    "        'review_clean':\n",
    "        list,\n",
    "        'nb_sentences':\n",
    "        'mean',\n",
    "        'nb_review':\n",
    "        'mean',\n",
    "        'metric sim_ratio':\n",
    "        'mean',\n",
    "        'reviews_heatmaps_html':\n",
    "        list,\n",
    "        'reviews_heatmaps_polarity':\n",
    "        list\n",
    "    })\n",
    "\n",
    "    #print(\"check\")\n",
    "    #print(type(summary_reconstructed))\n",
    "    #print(summary_reconstructed.columns)\n",
    "    #print(summary_reconstructed.shape)\n",
    "    output_json = summary_reconstructed.to_dict()\n",
    "    return output_json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80e105e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22 µs, sys: 12 µs, total: 34 µs\n",
      "Wall time: 52.9 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "text = \"I want a burger\"\n",
    "n_best=10\n",
    "n_prox=3000\n",
    "min_review=10\n",
    "\n",
    "\n",
    "min_review = int(min_review)\n",
    "if pd.isna(n_prox):\n",
    "    pass\n",
    "else:\n",
    "    n_prox = int(n_prox)\n",
    "n_best = int(n_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af73e022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "CPU times: user 1.6 s, sys: 6.49 s, total: 8.09 s\n",
      "Wall time: 1min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#loading datasets\n",
    "results = compute_sim_df(text, embedding, n_prox, min_review)\n",
    "summary = summary_reviews(results, n_best)\n",
    "results['is_sim'] = 1\n",
    "summary['is_in_summary'] = 1\n",
    "results_trimed = results.drop(\n",
    "        columns=['alias', 'rate', 'review_sentences'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17e9b98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af3ab54e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results_trimed' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'results_trimed' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#merging datasets and house cleaning\n",
    "\n",
    "tmp_df = reviews_dataset.merge(results_trimed,\n",
    "                                   on='review_clean',\n",
    "                                   how='left')\n",
    "tmp_df['is_sim'].fillna(0, inplace=True)\n",
    "all_df = tmp_df.merge(summary, on='alias', how='left')\n",
    "all_df.fillna(0, inplace=True)\n",
    "all_df = all_df[all_df[\"is_in_summary\"]==1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f690775a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.35 s, sys: 245 ms, total: 2.6 s\n",
      "Wall time: 2.1 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<timed exec>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#apply heatmap for html and polarity score\n",
    "all_df[0:22]['reviews_heatmaps_html'] = all_df[0:100].apply(apply_heatmap_html,axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "64d4bed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c99ca3f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span style='background-color:rgba(0,188.45059901475906,0,0.6)'>\"i still eat a burger at a counter with ketchup dripping down my face </span><span style='background-color:rgba(0,136.9554202258587,0,0.6)'>\" - scarlett johansson burgers in paris </span><span style='background-color:rgba(0,55.36541551351547,0,0.6)'> oui, why of course </span><span style='background-color:rgba(0,139.38138484954834,0,0.6)'> after parisian wanderlusting all day i was jonesing for a burger </span><span style='background-color:rgba(0,82.12757706642151,0,0.6)'> oui, oui </span><span style='background-color:rgba(0,194.45250615477562,0,0.6)'> not escargot or caviar, but a burger, please </span><span style='background-color:rgba(0,73.62015277147293,0,0.6)'> oh </span><span style='background-color:rgba(0,56.8967941403389,0,0.6)'> yet, i didn't come to paris specifically for the burgers lol, fortunately my trusty yelp app helped me on my search </span><span style='background-color:rgba(0,63.372893035411835,0,0.6)'> i came across several restaurants that served burgers, but decided on a french chain restaurant called \"blend\" </span><span style='background-color:rgba(0,100.90329676866531,0,0.6)'> it was within walking distance from my b&b and it seemed euros affordable </span><span style='background-color:rgba(0,57.64906257390976,0,0.6)'> ohhh scarlett </span><span style='background-color:rgba(0,40.86568236351013,0,0.6)'> i walked in to a busy scene </span><span style='background-color:rgba(0,0.0,0,0.6)'> it's very popular as a take out and delivery spot, but also the dine-in area was open too </span><span style='background-color:rgba(0,15.105648636817932,0,0.6)'> i chose to dine-in and told i could sit anywhere with menu in hand </span><span style='background-color:rgba(0,108.07190090417862,0,0.6)'> fortunately i already perused the menu virtually, so almost immediately i ordered: - cheesy - sweet potato fries and a glass of - côtes du rhône the \"cheesy\" was definitely french lol </span><span style='background-color:rgba(0,141.28175407648087,0,0.6)'> compotée de cheddar affiné mois et bacon fumé, ketchup blend oignons frits, zucchini pickles, salade iceberg </span><span style='background-color:rgba(0,172.61313244700432,0,0.6)'> the month old cheddar had a nice zing and the excessive shredded lettuce was interesting lol, yet overall it was delicious and paired well with my côtes du rhône and sweet potato fries </span><span style='background-color:rgba(0,127.16060221195221,0,0.6)'> combos available on weekends </span><span style='background-color:rgba(0,109.18695867061615,0,0.6)'> the young lady who took my order was cute as a young scarlett with a touch of haute couture </span><span style='background-color:rgba(0,14.151474237442017,0,0.6)'> friendly staff each at least bilingual </span><span style='background-color:rgba(0,70.9977462887764,0,0.6)'> the food tho resembling american was quite french </span><span style='background-color:rgba(0,26.865242421627045,0,0.6)'> and when in paris i'm okay with that </span><span style='background-color:rgba(0,138.15576821565628,0,0.6)'> au revoir </span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(all_df.iloc[2]['reviews_heatmaps_html'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "09598a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "A.to_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7937091b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 84.8 ms, sys: 168 ms, total: 253 ms\n",
      "Wall time: 331 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "all_df['reviews_heatmaps_html'] = all_df[0:2].apply(apply_heatmap_html,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dc14a083",
   "metadata": {},
   "outputs": [],
   "source": [
    "A= all_df['reviews_heatmaps_html'] \n",
    "A.to_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "599be943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 32 s, sys: 3.48 s, total: 35.5 s\n",
      "Wall time: 35.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "all_df['reviews_heatmaps_polarity'] = all_df.apply(apply_heatmap_polarity, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "53d66676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/FOBO/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1054\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1055\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1056\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1057\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/FOBO/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    933\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 935\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    936\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    937\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/FOBO/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/lib/python3.8/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    437\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/lib/python3.8/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "check = Parallel(n_jobs=-1)(delayed(apply_heatmap_html) for i in all_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "49982e14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_clean</th>\n",
       "      <th>alias</th>\n",
       "      <th>rate</th>\n",
       "      <th>review_sentences</th>\n",
       "      <th>embedding</th>\n",
       "      <th>review_sentences_trimed</th>\n",
       "      <th>date</th>\n",
       "      <th>sim_s</th>\n",
       "      <th>rate_filtered_x</th>\n",
       "      <th>review_filtered</th>\n",
       "      <th>...</th>\n",
       "      <th>ratio</th>\n",
       "      <th>metric</th>\n",
       "      <th>is_sim</th>\n",
       "      <th>reviews</th>\n",
       "      <th>nb_sentences</th>\n",
       "      <th>nb_review</th>\n",
       "      <th>metric sim_ratio</th>\n",
       "      <th>rate_filtered_y</th>\n",
       "      <th>is_in_summary</th>\n",
       "      <th>reviews_heatmaps_polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>\"i still eat a burger at a counter with ketchu...</td>\n",
       "      <td>blend-paris-26</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[\"i still eat a burger at a counter with ketch...</td>\n",
       "      <td>[[0.04524126, 0.093474865, 0.018982986, -0.091...</td>\n",
       "      <td>[\"i still eat a burger at a counter with ketch...</td>\n",
       "      <td>2021-01-26</td>\n",
       "      <td>0.689196</td>\n",
       "      <td>3.928571</td>\n",
       "      <td>61.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.753086</td>\n",
       "      <td>0.279523</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{after visiting the louvre museum we looked fo...</td>\n",
       "      <td>98.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0.279523</td>\n",
       "      <td>3.928571</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.979778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>\"i still eat a burger at a counter with ketchu...</td>\n",
       "      <td>blend-paris-26</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[\"i still eat a burger at a counter with ketch...</td>\n",
       "      <td>[[0.04524126, 0.093474865, 0.018982986, -0.091...</td>\n",
       "      <td>[\"i still eat a burger at a counter with ketch...</td>\n",
       "      <td>2021-01-26</td>\n",
       "      <td>0.625217</td>\n",
       "      <td>3.928571</td>\n",
       "      <td>61.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.753086</td>\n",
       "      <td>0.279523</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{after visiting the louvre museum we looked fo...</td>\n",
       "      <td>98.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0.279523</td>\n",
       "      <td>3.928571</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.979778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>\"i still eat a burger at a counter with ketchu...</td>\n",
       "      <td>blend-paris-26</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[\"i still eat a burger at a counter with ketch...</td>\n",
       "      <td>[[0.04524126, 0.093474865, 0.018982986, -0.091...</td>\n",
       "      <td>[\"i still eat a burger at a counter with ketch...</td>\n",
       "      <td>2021-01-26</td>\n",
       "      <td>0.440658</td>\n",
       "      <td>3.928571</td>\n",
       "      <td>61.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.753086</td>\n",
       "      <td>0.279523</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{after visiting the louvre museum we looked fo...</td>\n",
       "      <td>98.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0.279523</td>\n",
       "      <td>3.928571</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.979778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>a \"french\" take on an amazing burger joint but...</td>\n",
       "      <td>blend-paris-26</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[a \"french\" take on an amazing burger joint bu...</td>\n",
       "      <td>[[0.038462874, -0.015068263, 0.021961713, -0.0...</td>\n",
       "      <td>[a \"french\" take on an amazing burger joint bu...</td>\n",
       "      <td>2012-03-04</td>\n",
       "      <td>0.409594</td>\n",
       "      <td>3.928571</td>\n",
       "      <td>61.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.753086</td>\n",
       "      <td>0.279523</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{after visiting the louvre museum we looked fo...</td>\n",
       "      <td>98.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0.279523</td>\n",
       "      <td>3.928571</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.974979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>a cool little (and i mean little) gourmet burg...</td>\n",
       "      <td>blend-paris-26</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[a cool little (and i mean little) gourmet bur...</td>\n",
       "      <td>[[0.049561992, 0.009552067, 0.010170949, -0.01...</td>\n",
       "      <td>[a cool little (and i mean little) gourmet bur...</td>\n",
       "      <td>2015-03-02</td>\n",
       "      <td>0.520061</td>\n",
       "      <td>3.928571</td>\n",
       "      <td>61.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.753086</td>\n",
       "      <td>0.279523</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{after visiting the louvre museum we looked fo...</td>\n",
       "      <td>98.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0.279523</td>\n",
       "      <td>3.928571</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.975982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56340</th>\n",
       "      <td>wow! great burger. in the quest to find the be...</td>\n",
       "      <td>big-fernand-paris-12</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[wow,  great burger,  in the quest to find the...</td>\n",
       "      <td>[[-0.02499111, 0.07090064, -0.033703253, 0.040...</td>\n",
       "      <td>[wow,  great burger,  in the quest to find the...</td>\n",
       "      <td>2013-03-05</td>\n",
       "      <td>0.564804</td>\n",
       "      <td>4.162162</td>\n",
       "      <td>21.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.257047</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{it's a crazy burger place! line was out the d...</td>\n",
       "      <td>37.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.257047</td>\n",
       "      <td>4.162162</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.978563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56350</th>\n",
       "      <td>wow! if you really like burgers and you want y...</td>\n",
       "      <td>little-cantine-paris</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[wow,  if you really like burgers and you want...</td>\n",
       "      <td>[[-0.02499111, 0.07090064, -0.033703253, 0.040...</td>\n",
       "      <td>[wow,  if you really like burgers and you want...</td>\n",
       "      <td>2018-08-15</td>\n",
       "      <td>0.554000</td>\n",
       "      <td>4.675676</td>\n",
       "      <td>27.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.586957</td>\n",
       "      <td>0.254946</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{amazing burger! get the dude burger -- cheese...</td>\n",
       "      <td>37.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.254946</td>\n",
       "      <td>4.675676</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.966912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56351</th>\n",
       "      <td>wow! if you really like burgers and you want y...</td>\n",
       "      <td>little-cantine-paris</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[wow,  if you really like burgers and you want...</td>\n",
       "      <td>[[-0.02499111, 0.07090064, -0.033703253, 0.040...</td>\n",
       "      <td>[wow,  if you really like burgers and you want...</td>\n",
       "      <td>2018-08-15</td>\n",
       "      <td>0.413223</td>\n",
       "      <td>4.675676</td>\n",
       "      <td>27.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.586957</td>\n",
       "      <td>0.254946</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{amazing burger! get the dude burger -- cheese...</td>\n",
       "      <td>37.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.254946</td>\n",
       "      <td>4.675676</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.966912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57000</th>\n",
       "      <td>young and hip crowd..went around : and there w...</td>\n",
       "      <td>blend-paris-26</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[young and hip crowd, went around : and there ...</td>\n",
       "      <td>[[-0.018133149, -0.011460958, 0.014708627, -0....</td>\n",
       "      <td>[young and hip crowd, went around : and there ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{after visiting the louvre museum we looked fo...</td>\n",
       "      <td>98.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0.279523</td>\n",
       "      <td>3.928571</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57085</th>\n",
       "      <td>yumbly bumbly! i went here the other week on a...</td>\n",
       "      <td>big-fernand-paris-12</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[yumbly bumbly,  i went here the other week on...</td>\n",
       "      <td>[[0.051983755, 0.051327255, 0.005685607, -0.02...</td>\n",
       "      <td>[yumbly bumbly,  i went here the other week on...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{it's a crazy burger place! line was out the d...</td>\n",
       "      <td>37.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.257047</td>\n",
       "      <td>4.162162</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.972342</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>399 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            review_clean  \\\n",
       "28     \"i still eat a burger at a counter with ketchu...   \n",
       "29     \"i still eat a burger at a counter with ketchu...   \n",
       "30     \"i still eat a burger at a counter with ketchu...   \n",
       "285    a \"french\" take on an amazing burger joint but...   \n",
       "404    a cool little (and i mean little) gourmet burg...   \n",
       "...                                                  ...   \n",
       "56340  wow! great burger. in the quest to find the be...   \n",
       "56350  wow! if you really like burgers and you want y...   \n",
       "56351  wow! if you really like burgers and you want y...   \n",
       "57000  young and hip crowd..went around : and there w...   \n",
       "57085  yumbly bumbly! i went here the other week on a...   \n",
       "\n",
       "                      alias  rate  \\\n",
       "28           blend-paris-26   4.0   \n",
       "29           blend-paris-26   4.0   \n",
       "30           blend-paris-26   4.0   \n",
       "285          blend-paris-26   4.0   \n",
       "404          blend-paris-26   4.0   \n",
       "...                     ...   ...   \n",
       "56340  big-fernand-paris-12   4.0   \n",
       "56350  little-cantine-paris   5.0   \n",
       "56351  little-cantine-paris   5.0   \n",
       "57000        blend-paris-26   3.0   \n",
       "57085  big-fernand-paris-12   4.0   \n",
       "\n",
       "                                        review_sentences  \\\n",
       "28     [\"i still eat a burger at a counter with ketch...   \n",
       "29     [\"i still eat a burger at a counter with ketch...   \n",
       "30     [\"i still eat a burger at a counter with ketch...   \n",
       "285    [a \"french\" take on an amazing burger joint bu...   \n",
       "404    [a cool little (and i mean little) gourmet bur...   \n",
       "...                                                  ...   \n",
       "56340  [wow,  great burger,  in the quest to find the...   \n",
       "56350  [wow,  if you really like burgers and you want...   \n",
       "56351  [wow,  if you really like burgers and you want...   \n",
       "57000  [young and hip crowd, went around : and there ...   \n",
       "57085  [yumbly bumbly,  i went here the other week on...   \n",
       "\n",
       "                                               embedding  \\\n",
       "28     [[0.04524126, 0.093474865, 0.018982986, -0.091...   \n",
       "29     [[0.04524126, 0.093474865, 0.018982986, -0.091...   \n",
       "30     [[0.04524126, 0.093474865, 0.018982986, -0.091...   \n",
       "285    [[0.038462874, -0.015068263, 0.021961713, -0.0...   \n",
       "404    [[0.049561992, 0.009552067, 0.010170949, -0.01...   \n",
       "...                                                  ...   \n",
       "56340  [[-0.02499111, 0.07090064, -0.033703253, 0.040...   \n",
       "56350  [[-0.02499111, 0.07090064, -0.033703253, 0.040...   \n",
       "56351  [[-0.02499111, 0.07090064, -0.033703253, 0.040...   \n",
       "57000  [[-0.018133149, -0.011460958, 0.014708627, -0....   \n",
       "57085  [[0.051983755, 0.051327255, 0.005685607, -0.02...   \n",
       "\n",
       "                                 review_sentences_trimed        date  \\\n",
       "28     [\"i still eat a burger at a counter with ketch...  2021-01-26   \n",
       "29     [\"i still eat a burger at a counter with ketch...  2021-01-26   \n",
       "30     [\"i still eat a burger at a counter with ketch...  2021-01-26   \n",
       "285    [a \"french\" take on an amazing burger joint bu...  2012-03-04   \n",
       "404    [a cool little (and i mean little) gourmet bur...  2015-03-02   \n",
       "...                                                  ...         ...   \n",
       "56340  [wow,  great burger,  in the quest to find the...  2013-03-05   \n",
       "56350  [wow,  if you really like burgers and you want...  2018-08-15   \n",
       "56351  [wow,  if you really like burgers and you want...  2018-08-15   \n",
       "57000  [young and hip crowd, went around : and there ...           0   \n",
       "57085  [yumbly bumbly,  i went here the other week on...           0   \n",
       "\n",
       "          sim_s  rate_filtered_x  review_filtered  ...     ratio    metric  \\\n",
       "28     0.689196         3.928571             61.0  ...  0.753086  0.279523   \n",
       "29     0.625217         3.928571             61.0  ...  0.753086  0.279523   \n",
       "30     0.440658         3.928571             61.0  ...  0.753086  0.279523   \n",
       "285    0.409594         3.928571             61.0  ...  0.753086  0.279523   \n",
       "404    0.520061         3.928571             61.0  ...  0.753086  0.279523   \n",
       "...         ...              ...              ...  ...       ...       ...   \n",
       "56340  0.564804         4.162162             21.0  ...  0.677419  0.257047   \n",
       "56350  0.554000         4.675676             27.0  ...  0.586957  0.254946   \n",
       "56351  0.413223         4.675676             27.0  ...  0.586957  0.254946   \n",
       "57000  0.000000         0.000000              0.0  ...  0.000000  0.000000   \n",
       "57085  0.000000         0.000000              0.0  ...  0.000000  0.000000   \n",
       "\n",
       "       is_sim                                            reviews  \\\n",
       "28        1.0  {after visiting the louvre museum we looked fo...   \n",
       "29        1.0  {after visiting the louvre museum we looked fo...   \n",
       "30        1.0  {after visiting the louvre museum we looked fo...   \n",
       "285       1.0  {after visiting the louvre museum we looked fo...   \n",
       "404       1.0  {after visiting the louvre museum we looked fo...   \n",
       "...       ...                                                ...   \n",
       "56340     1.0  {it's a crazy burger place! line was out the d...   \n",
       "56350     1.0  {amazing burger! get the dude burger -- cheese...   \n",
       "56351     1.0  {amazing burger! get the dude burger -- cheese...   \n",
       "57000     0.0  {after visiting the louvre museum we looked fo...   \n",
       "57085     0.0  {it's a crazy burger place! line was out the d...   \n",
       "\n",
       "       nb_sentences  nb_review metric sim_ratio  rate_filtered_y  \\\n",
       "28             98.0       61.0         0.279523         3.928571   \n",
       "29             98.0       61.0         0.279523         3.928571   \n",
       "30             98.0       61.0         0.279523         3.928571   \n",
       "285            98.0       61.0         0.279523         3.928571   \n",
       "404            98.0       61.0         0.279523         3.928571   \n",
       "...             ...        ...              ...              ...   \n",
       "56340          37.0       21.0         0.257047         4.162162   \n",
       "56350          37.0       27.0         0.254946         4.675676   \n",
       "56351          37.0       27.0         0.254946         4.675676   \n",
       "57000          98.0       61.0         0.279523         3.928571   \n",
       "57085          37.0       21.0         0.257047         4.162162   \n",
       "\n",
       "       is_in_summary  reviews_heatmaps_polarity  \n",
       "28               1.0                   0.979778  \n",
       "29               1.0                   0.979778  \n",
       "30               1.0                   0.979778  \n",
       "285              1.0                   0.974979  \n",
       "404              1.0                   0.975982  \n",
       "...              ...                        ...  \n",
       "56340            1.0                   0.978563  \n",
       "56350            1.0                   0.966912  \n",
       "56351            1.0                   0.966912  \n",
       "57000            1.0                   0.000000  \n",
       "57085            1.0                   0.972342  \n",
       "\n",
       "[399 rows x 23 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17df9568",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarities_parra = Parallel(n_jobs=-1)(\n",
    "        delayed(util.cos_sim)(input_encoded, split_embedding)\n",
    "        for split_embedding in embedding_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "846ca739",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65aaa5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Parallel(n_jobs=-1)(delayed(apply_heatmap_polarity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d14efe1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.5 ms, sys: 4.04 ms, total: 15.6 ms\n",
      "Wall time: 20.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "####  metrics for the val of the request\n",
    "all_df['request_metric'] = all_df[(all_df['is_in_summary'] == 1) & (\n",
    "        all_df['is_sim'] == 1)]['nb_sentences'].sum() *100 /3000\n",
    "summary_reconstructed = all_df.groupby('alias').agg({\n",
    "        'review_clean':\n",
    "        list,\n",
    "        'nb_sentences':\n",
    "        'mean',\n",
    "        'nb_review':\n",
    "        'mean',\n",
    "        'metric sim_ratio':\n",
    "        'mean',\n",
    "        'reviews_heatmaps_html':\n",
    "        list,\n",
    "        'reviews_heatmaps_polarity':\n",
    "        list\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "67b9b141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.11 ms, sys: 119 µs, total: 1.23 ms\n",
      "Wall time: 1.21 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "    #print(\"check\")\n",
    "    #print(type(summary_reconstructed))\n",
    "    #print(summary_reconstructed.columns)\n",
    "    #print(summary_reconstructed.shape)\n",
    "output_json = summary_reconstructed.to_dict()\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7dcda4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e108ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c33767",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
