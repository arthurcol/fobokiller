{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f25a83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "48e44822",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import tensorflow\n",
    "import pickle\n",
    "import os\n",
    "from  fobokiller.cosim import load_embedding, model, compute_sim_df\n",
    "from joblib import Parallel,delayed\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4afb5b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = load_embedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2863185a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.6 s, sys: 4.74 s, total: 6.33 s\n",
      "Wall time: 1min 16s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alias</th>\n",
       "      <th>date</th>\n",
       "      <th>rate</th>\n",
       "      <th>review_clean</th>\n",
       "      <th>review_sentences</th>\n",
       "      <th>sim_s</th>\n",
       "      <th>rate_filtered</th>\n",
       "      <th>review_filtered</th>\n",
       "      <th>sim_r</th>\n",
       "      <th>rate_all</th>\n",
       "      <th>review_all</th>\n",
       "      <th>ratio</th>\n",
       "      <th>metric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>breakfast-in-america-2-paris</td>\n",
       "      <td>2017-05-04</td>\n",
       "      <td>4</td>\n",
       "      <td>the reason yelp exists. what a wonderful disco...</td>\n",
       "      <td>want a proper hamburger</td>\n",
       "      <td>0.738675</td>\n",
       "      <td>4.157895</td>\n",
       "      <td>16</td>\n",
       "      <td>0.480181</td>\n",
       "      <td>3.881956</td>\n",
       "      <td>82</td>\n",
       "      <td>0.195122</td>\n",
       "      <td>0.077914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pny-burger-oberkampf-paris</td>\n",
       "      <td>2019-06-05</td>\n",
       "      <td>2</td>\n",
       "      <td>i love burgers. my go to meal: burger. this pl...</td>\n",
       "      <td>i love burgers</td>\n",
       "      <td>0.713686</td>\n",
       "      <td>3.444444</td>\n",
       "      <td>12</td>\n",
       "      <td>0.511917</td>\n",
       "      <td>3.844444</td>\n",
       "      <td>18</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.235103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>l-arpège-paris-2</td>\n",
       "      <td>2016-01-19</td>\n",
       "      <td>3</td>\n",
       "      <td>l'arpege is france's -michelin starred restaur...</td>\n",
       "      <td>i want beef</td>\n",
       "      <td>0.705174</td>\n",
       "      <td>3.285714</td>\n",
       "      <td>6</td>\n",
       "      <td>0.521521</td>\n",
       "      <td>3.808692</td>\n",
       "      <td>152</td>\n",
       "      <td>0.039474</td>\n",
       "      <td>0.013528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hippopotamus-paris-13</td>\n",
       "      <td>2018-05-28</td>\n",
       "      <td>5</td>\n",
       "      <td>in paris with my husband for my honeymoon. we ...</td>\n",
       "      <td>get the burger</td>\n",
       "      <td>0.703004</td>\n",
       "      <td>3.750000</td>\n",
       "      <td>4</td>\n",
       "      <td>0.504269</td>\n",
       "      <td>2.227273</td>\n",
       "      <td>21</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>0.072038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>h-a-n-d-paris-2</td>\n",
       "      <td>2017-07-04</td>\n",
       "      <td>1</td>\n",
       "      <td>absolutly horrid. ordered a burger only to bit...</td>\n",
       "      <td>if you want a burger you're better off going ...</td>\n",
       "      <td>0.698962</td>\n",
       "      <td>2.545455</td>\n",
       "      <td>7</td>\n",
       "      <td>0.468972</td>\n",
       "      <td>2.751678</td>\n",
       "      <td>20</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.083562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>le-relais-de-venise-l-entrecôte-paris-2</td>\n",
       "      <td>2015-02-06</td>\n",
       "      <td>4</td>\n",
       "      <td>steak, fries, wine. questions? without a doubt...</td>\n",
       "      <td>steak, fries, wine</td>\n",
       "      <td>0.407238</td>\n",
       "      <td>4.304348</td>\n",
       "      <td>23</td>\n",
       "      <td>0.442410</td>\n",
       "      <td>4.208922</td>\n",
       "      <td>142</td>\n",
       "      <td>0.161972</td>\n",
       "      <td>0.061688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>le-chateaubriand-paris</td>\n",
       "      <td>2016-06-18</td>\n",
       "      <td>3</td>\n",
       "      <td>dinner for . - ambiance () cozy and modern, bu...</td>\n",
       "      <td>dinner for</td>\n",
       "      <td>0.407228</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>3</td>\n",
       "      <td>0.409406</td>\n",
       "      <td>3.808278</td>\n",
       "      <td>163</td>\n",
       "      <td>0.018405</td>\n",
       "      <td>0.006530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>le-minipalais-paris</td>\n",
       "      <td>2011-08-05</td>\n",
       "      <td>3</td>\n",
       "      <td>dinner for . the apps were delicious and flavo...</td>\n",
       "      <td>dinner for</td>\n",
       "      <td>0.407228</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.417131</td>\n",
       "      <td>3.399132</td>\n",
       "      <td>43</td>\n",
       "      <td>0.069767</td>\n",
       "      <td>0.011641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>les-galopins-paris</td>\n",
       "      <td>2018-09-20</td>\n",
       "      <td>5</td>\n",
       "      <td>called the restaurant and between our language...</td>\n",
       "      <td>more like dinner for \"\"</td>\n",
       "      <td>0.407223</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.466899</td>\n",
       "      <td>4.816327</td>\n",
       "      <td>5</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.093380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>ferdi-paris</td>\n",
       "      <td>2019-10-20</td>\n",
       "      <td>5</td>\n",
       "      <td>finally we were able to find a table at ferdi....</td>\n",
       "      <td>when the burger arrived, my daughter ended up...</td>\n",
       "      <td>0.407214</td>\n",
       "      <td>4.285714</td>\n",
       "      <td>34</td>\n",
       "      <td>0.476502</td>\n",
       "      <td>3.764218</td>\n",
       "      <td>93</td>\n",
       "      <td>0.365591</td>\n",
       "      <td>0.149318</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        alias        date  rate  \\\n",
       "0                breakfast-in-america-2-paris  2017-05-04     4   \n",
       "1                  pny-burger-oberkampf-paris  2019-06-05     2   \n",
       "2                            l-arpège-paris-2  2016-01-19     3   \n",
       "3                       hippopotamus-paris-13  2018-05-28     5   \n",
       "4                             h-a-n-d-paris-2  2017-07-04     1   \n",
       "...                                       ...         ...   ...   \n",
       "2995  le-relais-de-venise-l-entrecôte-paris-2  2015-02-06     4   \n",
       "2996                   le-chateaubriand-paris  2016-06-18     3   \n",
       "2997                      le-minipalais-paris  2011-08-05     3   \n",
       "2998                       les-galopins-paris  2018-09-20     5   \n",
       "2999                              ferdi-paris  2019-10-20     5   \n",
       "\n",
       "                                           review_clean  \\\n",
       "0     the reason yelp exists. what a wonderful disco...   \n",
       "1     i love burgers. my go to meal: burger. this pl...   \n",
       "2     l'arpege is france's -michelin starred restaur...   \n",
       "3     in paris with my husband for my honeymoon. we ...   \n",
       "4     absolutly horrid. ordered a burger only to bit...   \n",
       "...                                                 ...   \n",
       "2995  steak, fries, wine. questions? without a doubt...   \n",
       "2996  dinner for . - ambiance () cozy and modern, bu...   \n",
       "2997  dinner for . the apps were delicious and flavo...   \n",
       "2998  called the restaurant and between our language...   \n",
       "2999  finally we were able to find a table at ferdi....   \n",
       "\n",
       "                                       review_sentences     sim_s  \\\n",
       "0                               want a proper hamburger  0.738675   \n",
       "1                                        i love burgers  0.713686   \n",
       "2                                           i want beef  0.705174   \n",
       "3                                        get the burger  0.703004   \n",
       "4      if you want a burger you're better off going ...  0.698962   \n",
       "...                                                 ...       ...   \n",
       "2995                                 steak, fries, wine  0.407238   \n",
       "2996                                        dinner for   0.407228   \n",
       "2997                                        dinner for   0.407228   \n",
       "2998                            more like dinner for \"\"  0.407223   \n",
       "2999   when the burger arrived, my daughter ended up...  0.407214   \n",
       "\n",
       "      rate_filtered  review_filtered     sim_r  rate_all  review_all  \\\n",
       "0          4.157895               16  0.480181  3.881956          82   \n",
       "1          3.444444               12  0.511917  3.844444          18   \n",
       "2          3.285714                6  0.521521  3.808692         152   \n",
       "3          3.750000                4  0.504269  2.227273          21   \n",
       "4          2.545455                7  0.468972  2.751678          20   \n",
       "...             ...              ...       ...       ...         ...   \n",
       "2995       4.304348               23  0.442410  4.208922         142   \n",
       "2996       4.333333                3  0.409406  3.808278         163   \n",
       "2997       2.000000                3  0.417131  3.399132          43   \n",
       "2998       5.000000                1  0.466899  4.816327           5   \n",
       "2999       4.285714               34  0.476502  3.764218          93   \n",
       "\n",
       "         ratio    metric  \n",
       "0     0.195122  0.077914  \n",
       "1     0.666667  0.235103  \n",
       "2     0.039474  0.013528  \n",
       "3     0.190476  0.072038  \n",
       "4     0.350000  0.083562  \n",
       "...        ...       ...  \n",
       "2995  0.161972  0.061688  \n",
       "2996  0.018405  0.006530  \n",
       "2997  0.069767  0.011641  \n",
       "2998  0.200000  0.093380  \n",
       "2999  0.365591  0.149318  \n",
       "\n",
       "[3000 rows x 13 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "compute_sim_df(\"I want a burger\", embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "21af808a",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_encoded = model.encode(text)\n",
    "embedding_split = np.array_split(embedding,\n",
    "                                     multiprocessing.cpu_count() - 1)\n",
    "\n",
    "similarities_parra = Parallel(n_jobs=-1)(\n",
    "        delayed(util.cos_sim)(input_encoded, split_embedding)\n",
    "        for split_embedding in embedding_split)\n",
    "    # // powa !\n",
    "similarities = tensorflow.concat(similarities_parra, 1)\n",
    "    #similarities = util.cos_sim(input_encoded, np.array(embedding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "20c01cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarities_old = util.cos_sim(input_encoded, np.array(embedding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ac162b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "dc30a3b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1825, 0.1664, 0.2353,  ..., 0.3719, 0.2296, 0.0928]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat(similarities_parra,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a9cc2ebc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1825, 0.1664, 0.2353,  ..., 0.3719, 0.2296, 0.0928]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarities_old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee481a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sim = df_full.assign(sim=similarities.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4315d833",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_sim_df(text, embedding, n_prox=3000, min_review=0):\n",
    "    input_encoded = model.encode(text)\n",
    "    embedding_split = np.array_split(embedding,\n",
    "                                     multiprocessing.cpu_count() - 1)\n",
    "\n",
    "    similarities_parra = Parallel(n_jobs=-1)(\n",
    "        delayed(util.cos_sim)(input_encoded, split_embedding)\n",
    "        for split_embedding in embedding_split)\n",
    "    # // powa !\n",
    "    similarities = tensorflow.concat(similarities_parra, 1)\n",
    "    #similarities = util.cos_sim(input_encoded, np.array(embedding))\n",
    "\n",
    "    df_sim = df_full.assign(sim=similarities.T)\n",
    "\n",
    "    if n_prox:\n",
    "        df_sentences = df_sim.sort_values('sim', ascending=False)[:n_prox]\n",
    "    else:\n",
    "        df_sentences = df_sim.sort_values('sim', ascending=False)\n",
    "\n",
    "    df_agg = df_sentences.groupby('alias').agg({\n",
    "        'rate': 'mean',\n",
    "        'review': 'nunique',\n",
    "        #'review_sentences':'first',\n",
    "        #'review_clean':lambda txt: ' // '.join(txt),\n",
    "        'sim': 'mean'\n",
    "    })\n",
    "\n",
    "    df_resto = df_agg.merge(df_all_resto,\n",
    "                            on='alias',\n",
    "                            how='left',\n",
    "                            suffixes=('_filtered', '_all')).reset_index()\n",
    "\n",
    "    df_resto['ratio'] = df_resto['review_filtered'] / df_resto['review_all']\n",
    "\n",
    "    df_resto = df_resto.sort_values('ratio')\n",
    "    df_resto = df_resto[df_resto['review_all'] > min_review]\n",
    "\n",
    "    df_final = df_sentences.merge(df_resto,\n",
    "                                  on='alias',\n",
    "                                  how='left',\n",
    "                                  suffixes=('_s', '_r'))\n",
    "\n",
    "    df_final['metric'] = df_final['ratio'] * df_final['sim_r'] * df_final[\n",
    "        'rate_filtered'] / 5\n",
    "\n",
    "    df_final.drop(columns=['review'], inplace=True)\n",
    "\n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4f74c1c0",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "\n        'EagerTensor' object has no attribute 'T'.\n        If you are looking for numpy-related methods, please run the following:\n        from tensorflow.python.ops.numpy_ops import np_config\n        np_config.enable_numpy_behavior()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/s6/nxj_k6112bj7cnd89_8b9l0c0000gn/T/ipykernel_67297/773736109.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mA\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mcompute_sim_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"I want a burger\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/s6/nxj_k6112bj7cnd89_8b9l0c0000gn/T/ipykernel_67297/532360311.py\u001b[0m in \u001b[0;36mcompute_sim_df\u001b[0;34m(text, embedding, n_prox, min_review)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m#similarities = util.cos_sim(input_encoded, np.array(embedding))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mdf_sim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msimilarities\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mn_prox\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/FOBO/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    435\u001b[0m                 \"tolist\", \"data\"}:\n\u001b[1;32m    436\u001b[0m       \u001b[0;31m# TODO(wangpeng): Export the enable_numpy_behavior knob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 437\u001b[0;31m       raise AttributeError(\"\"\"\n\u001b[0m\u001b[1;32m    438\u001b[0m         \u001b[0;34m'{}'\u001b[0m \u001b[0mobject\u001b[0m \u001b[0mhas\u001b[0m \u001b[0mno\u001b[0m \u001b[0mattribute\u001b[0m \u001b[0;34m'{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m         \u001b[0mIf\u001b[0m \u001b[0myou\u001b[0m \u001b[0mare\u001b[0m \u001b[0mlooking\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mrelated\u001b[0m \u001b[0mmethods\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplease\u001b[0m \u001b[0mrun\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mfollowing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: \n        'EagerTensor' object has no attribute 'T'.\n        If you are looking for numpy-related methods, please run the following:\n        from tensorflow.python.ops.numpy_ops import np_config\n        np_config.enable_numpy_behavior()"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "A =compute_sim_df(\"I want a burger\",embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d199990b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "A =compute_sim_df(\"I want a burger\",embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84c38b63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-02 14:44:55.884637: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "embedding = load_embedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e5fc33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_resto = df_full.groupby('alias').agg({ 'rate':'mean',\n",
    "                                                'review':'nunique'\n",
    "                                            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35400cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_encoded = model.encode(\"I want a burger\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6847979c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.5 s, sys: 19.5 s, total: 25 s\n",
      "Wall time: 2min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"True\"\n",
    "similarities_simple = util.cos_sim(input_encoded, np.array(embedding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b00f744c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.28 s, sys: 20.9 s, total: 27.1 s\n",
      "Wall time: 1min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "similarities_simple = util.cos_sim(input_encoded, np.array(embedding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5ac17f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMPORTS ###\n",
    "\n",
    "#canonical\n",
    "from sys import path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "#words/sentences  preprocessing\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "#modeling\n",
    "from tensorflow.keras import models\n",
    "\n",
    "#cosim\n",
    "\n",
    "from fobokiller.cosim import load_embedding,compute_sim_df,summary_reviews\n",
    "\n",
    "def load_model():\n",
    "    #path_model = os.path.join(os.path.dirname(os.path.dirname(__file__)),'model_heatmap')\n",
    "    model = models.load_model(\"model_heatmap/\")\n",
    "    return model\n",
    "\n",
    "def load_reviews_dataset():\n",
    "    path_reviews_all = os.path.join(os.path.dirname(__file__),\n",
    "                                    'data/scrapping_cleaned_sentences.csv')\n",
    "    dataset = pd.read_csv(path_reviews_all,index_col=0)\n",
    "    embedding=load_embedding()\n",
    "    dataset = dataset.assign(embedding=[*np.array(embedding)])\n",
    "    dataset = dataset.groupby('review_clean').agg({\n",
    "                                                'alias': 'first',\n",
    "                                                'rate': 'mean',\n",
    "                                                'review_sentences': list,\n",
    "                                                'embedding': list,\n",
    "                                            }).reset_index()\n",
    "    dataset['review_sentences_trimed'] = dataset['review_sentences'].apply(\n",
    "        lambda list_: list_[:30])\n",
    "\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def creating_query_dataset(embedding,reviews_dataset,query, n_prox, min_review,n_best):\n",
    "    #loading data\n",
    "    results = compute_sim_df(query,embedding,n_prox=n_prox,min_review=min_review)\n",
    "    summary = summary_reviews(results,n_best=n_best)\n",
    "\n",
    "    #creating is_sim & is_in_summary columns\n",
    "    results['is_sim'] = 1\n",
    "    summary['is_in_summary'] = 1\n",
    "\n",
    "    #merging datasets\n",
    "    results_trimed = results.drop(columns=['alias', 'rate', 'review_sentences'])\n",
    "    tmp_df = reviews_dataset.merge(results_trimed, on='review_clean', how='left')\n",
    "    tmp_df['is_sim'].fillna(0, inplace=True)\n",
    "    all_df = tmp_df.merge(summary, on='alias', how='left')\n",
    "    all_df.fillna(0, inplace=True)\n",
    "\n",
    "    return all_df\n",
    "\n",
    "\n",
    "\n",
    "def heatmap_sentences(review_sentences, review_embedded, model):\n",
    "    #padding\n",
    "    review_embedded = pad_sequences([review_embedded],\n",
    "                                    dtype='float32',\n",
    "                                    padding='post',\n",
    "                                    maxlen=30)\n",
    "    # predict\n",
    "    preds = model.predict(review_embedded)\n",
    "    #gradient tape\n",
    "    with tf.GradientTape() as tape:\n",
    "        class_idx = np.argmax(preds[0]) #a priori useless always return 0\n",
    "        last_conv_layer = model.get_layer('conv1d')\n",
    "        iterate = tf.keras.models.Model([model.inputs],\n",
    "                                        [model.output, last_conv_layer.output])\n",
    "        model_out, last_conv_layer = iterate(review_embedded)\n",
    "        class_out = model_out[:, class_idx]\n",
    "        grads = tape.gradient(class_out, last_conv_layer)\n",
    "        pooled_grads = tf.reduce_mean(grads)\n",
    "\n",
    "    heatmap = tf.reduce_mean(tf.multiply(pooled_grads, last_conv_layer),\n",
    "                             axis=-1)\n",
    "    heatmap = np.maximum(heatmap, 0)\n",
    "    if np.max(heatmap) !=0: ### A VOIR LE SENS ?!\n",
    "        heatmap /= np.max(heatmap)\n",
    "\n",
    "    polarity_distance=np.max(heatmap[0])-np.min(heatmap[0])\n",
    "\n",
    "    html = \"\"\n",
    "    for i, j in enumerate(review_sentences):\n",
    "        html += f\"<span style='background-color:rgba(0,{255-heatmap[0][i]*255},0,0.6)'>{j} </span>\"\n",
    "\n",
    "    return html,polarity_distance\n",
    "\n",
    "model_heatmap = load_model()\n",
    "\n",
    "def apply_heatmap_html(df):\n",
    "    html_out,polarity_distance=heatmap_sentences(df['review_sentences_trimed'],\n",
    "                                                 df['embedding'],model_heatmap)\n",
    "    return html_out\n",
    "\n",
    "\n",
    "def apply_heatmap_polarity(df):\n",
    "    html_out, polarity_distance = heatmap_sentences(\n",
    "        df['review_sentences_trimed'], df['embedding'], model_heatmap)\n",
    "    return polarity_distance\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a1afda4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sr2(text, n_best=10, n_prox=3000, min_review=10):\n",
    "\n",
    "    #setting types\n",
    "    min_review = int(min_review)\n",
    "    if pd.isna(n_prox):\n",
    "        pass\n",
    "    else:\n",
    "        n_prox = int(n_prox)\n",
    "    n_best = int(n_best)\n",
    "\n",
    "    #loading datasets\n",
    "    results = compute_sim_df(text, embedding, n_prox, min_review)\n",
    "    summary = summary_reviews(results, n_best)\n",
    "    results['is_sim'] = 1\n",
    "    summary['is_in_summary'] = 1\n",
    "    results_trimed = results.drop(\n",
    "        columns=['alias', 'rate', 'review_sentences'])\n",
    "\n",
    "    #merging datasets and house cleaning\n",
    "\n",
    "    tmp_df = reviews_dataset.merge(results_trimed,\n",
    "                                   on='review_clean',\n",
    "                                   how='left')\n",
    "    tmp_df['is_sim'].fillna(0, inplace=True)\n",
    "    all_df = tmp_df.merge(summary, on='alias', how='left')\n",
    "    all_df.fillna(0, inplace=True)\n",
    "    all_df = all_df[all_df[\"is_in_summary\"]==1]\n",
    "\n",
    "    #apply heatmap for html and polarity score\n",
    "    all_df['reviews_heatmaps_html'] = all_df.apply(apply_heatmap_html,axis=1)\n",
    "    all_df['reviews_heatmaps_polarity'] = all_df.apply(apply_heatmap_polarity, axis=1)\n",
    "    ####  metrics for the val of the request\n",
    "    all_df['request_metric'] = all_df[(all_df['is_in_summary'] == 1) & (\n",
    "        all_df['is_sim'] == 1)]['nb_sentences'].sum() *100 /3000\n",
    "    summary_reconstructed = all_df.groupby('alias').agg({\n",
    "        'review_clean':\n",
    "        list,\n",
    "        'nb_sentences':\n",
    "        'mean',\n",
    "        'nb_review':\n",
    "        'mean',\n",
    "        'metric sim_ratio':\n",
    "        'mean',\n",
    "        'reviews_heatmaps_html':\n",
    "        list,\n",
    "        'reviews_heatmaps_polarity':\n",
    "        list\n",
    "    })\n",
    "\n",
    "    #print(\"check\")\n",
    "    #print(type(summary_reconstructed))\n",
    "    #print(summary_reconstructed.columns)\n",
    "    #print(summary_reconstructed.shape)\n",
    "    output_json = summary_reconstructed.to_dict()\n",
    "    return output_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "47c029bd",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "\n        'EagerTensor' object has no attribute 'T'.\n        If you are looking for numpy-related methods, please run the following:\n        from tensorflow.python.ops.numpy_ops import np_config\n        np_config.enable_numpy_behavior()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m/var/folders/s6/nxj_k6112bj7cnd89_8b9l0c0000gn/T/ipykernel_67297/3045289668.py\u001b[0m in \u001b[0;36msr2\u001b[0;34m(text, n_best, n_prox, min_review)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m#loading datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_sim_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_prox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_review\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0msummary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msummary_reviews\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_best\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'is_sim'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/fobokiller/fobokiller/cosim.py\u001b[0m in \u001b[0;36mcompute_sim_df\u001b[0;34m(text, embedding, n_prox, min_review)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;31m#similarities = util.cos_sim(input_encoded, np.array(embedding))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0mdf_sim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msimilarities\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mn_prox\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/FOBO/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    435\u001b[0m                 \"tolist\", \"data\"}:\n\u001b[1;32m    436\u001b[0m       \u001b[0;31m# TODO(wangpeng): Export the enable_numpy_behavior knob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 437\u001b[0;31m       raise AttributeError(\"\"\"\n\u001b[0m\u001b[1;32m    438\u001b[0m         \u001b[0;34m'{}'\u001b[0m \u001b[0mobject\u001b[0m \u001b[0mhas\u001b[0m \u001b[0mno\u001b[0m \u001b[0mattribute\u001b[0m \u001b[0;34m'{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m         \u001b[0mIf\u001b[0m \u001b[0myou\u001b[0m \u001b[0mare\u001b[0m \u001b[0mlooking\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mrelated\u001b[0m \u001b[0mmethods\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplease\u001b[0m \u001b[0mrun\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mfollowing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: \n        'EagerTensor' object has no attribute 'T'.\n        If you are looking for numpy-related methods, please run the following:\n        from tensorflow.python.ops.numpy_ops import np_config\n        np_config.enable_numpy_behavior()"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sr2(\"I want a burger\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f9f1dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
