{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a861b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f9b538",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87aa29f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f5476061",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aaf107f",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# api 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "bb870752",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 32.7 ms, sys: 9.26 ms, total: 41.9 ms\n",
      "Wall time: 4.82 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "response = requests.get(\"https://api9-2rnijzpfva-ew.a.run.app/summary_reviews?text=I%20want%20the%20best%20burger&n_best=10&n_prox=3000&min_review=3\").json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "19d030ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 45.8 ms, sys: 85.7 ms, total: 132 ms\n",
      "Wall time: 7.72 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "response = requests.get(\"https://api9-2rnijzpfva-ew.a.run.app/summary_reviews2?text=I%20want%20the%20best%20burger&n_best=5&n_prox=3000&min_review=3\").json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1736443",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "400c38ac",
   "metadata": {},
   "source": [
    "# api 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7a5da785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 36.1 ms, sys: 19.7 ms, total: 55.8 ms\n",
      "Wall time: 5.23 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "response = requests.get(\"https://api9-2rnijzpfva-ew.a.run.app/summary_reviews?text=I%20want%20the%20best%20burger&n_best=10&n_prox=3000&min_review=3\").json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f19bd619",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-02 16:53:50.435269: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from fobokiller.heatmap import load_reviews_dataset, heatmap_sentences, \\\n",
    "load_model,apply_heatmap_html,apply_heatmap_polarity\n",
    "\n",
    "from fastapi import FastAPI, Query\n",
    "from fastapi.middleware.cors import CORSMiddleware\n",
    "import pandas as pd\n",
    "from typing import List\n",
    "\n",
    "from fobokiller.cosim import compute_sim_df, load_embedding, summary_reviews\n",
    "#words/sentences  preprocessing\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras import backend as K\n",
    "#modeling\n",
    "from tensorflow import GradientTape\n",
    "import tensorflow as tf#modeling\n",
    "from tensorflow.keras import models, layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7b9a2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "resto_list = pd.read_csv(\"../api/final_resto_list.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b1baaee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "embedding = load_embedding()\n",
    "\n",
    "reviews_dataset = load_reviews_dataset()\n",
    "\n",
    "model_heatmap = load_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "abe8d19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "\n",
    "app.add_middleware(\n",
    "    CORSMiddleware,\n",
    "    allow_origins=[\"*\"],  # Allows all origins\n",
    "    allow_credentials=True,\n",
    "    allow_methods=[\"*\"],  # Allows all methods\n",
    "    allow_headers=[\"*\"],  # Allows all headers\n",
    ")\n",
    "\n",
    "\n",
    "temp =[]\n",
    "result = []\n",
    "\n",
    "@app.get(\"/\")\n",
    "def index():\n",
    "    return {\"greeting\": \"Hello world\"}\n",
    "\n",
    "\n",
    "#Input list of restaurant (alias)\n",
    "# detail\n",
    "@app.get(\"/detail\")\n",
    "def get_details(alias):\n",
    "\n",
    "    alias = [alias]\n",
    "    pd_liste = resto_list.loc[resto_list['alias'].isin(alias), :]\n",
    "    return pd_liste.to_dict()\n",
    "\n",
    "\n",
    "\n",
    "@app.get(\"/details/\")\n",
    "def read_items(alias: List[str] = Query(None)):\n",
    "    print(alias)\n",
    "    pd_liste = resto_list.loc[resto_list['alias'].isin(alias), :]\n",
    "    print(pd_liste)\n",
    "\n",
    "    return pd_liste.to_dict()\n",
    "\n",
    "@app.get(\"/summary_reviews\")\n",
    "def sr(text, n_best=10, n_prox=3000, min_review=0):\n",
    "    min_review = int(min_review)\n",
    "    print(type(n_prox))\n",
    "    if pd.isna(n_prox):\n",
    "        pass\n",
    "    else:\n",
    "\n",
    "        n_prox = int(n_prox)\n",
    "    temp = compute_sim_df(text, embedding, n_prox, min_review)\n",
    "    n_best = int(n_best)\n",
    "    result = summary_reviews(temp, n_best)\n",
    "    return result.to_dict()\n",
    "\n",
    "\n",
    "\n",
    "@app.get(\"/summary_reviews2\")\n",
    "def sr2(text, n_best=1, n_prox=3000, min_review=10):\n",
    "\n",
    "    #setting types\n",
    "    min_review = int(min_review)\n",
    "    if pd.isna(n_prox):\n",
    "        pass\n",
    "    else:\n",
    "        n_prox = int(n_prox)\n",
    "    n_best = int(n_best)\n",
    "\n",
    "    #loading datasets\n",
    "    results = compute_sim_df(text, embedding, n_prox, min_review)\n",
    "    summary = summary_reviews(results, n_best)\n",
    "    results['is_sim'] = 1\n",
    "    summary['is_in_summary'] = 1\n",
    "    results_trimed = results.drop(\n",
    "        columns=['alias', 'rate', 'review_sentences'])\n",
    "\n",
    "    #merging datasets and house cleaning\n",
    "\n",
    "    tmp_df = reviews_dataset.merge(results_trimed,\n",
    "                                   on='review_clean',\n",
    "                                   how='left')\n",
    "    tmp_df['is_sim'].fillna(0, inplace=True)\n",
    "    all_df = tmp_df.merge(summary, on='alias', how='left')\n",
    "    all_df.fillna(0, inplace=True)\n",
    "    all_df = all_df[all_df[\"is_in_summary\"]==1]\n",
    "\n",
    "    #apply heatmap for html and polarity score\n",
    "    all_df['reviews_heatmaps_html'] = all_df.apply(apply_heatmap_html,axis=1)\n",
    "    all_df['reviews_heatmaps_polarity'] = all_df.apply(apply_heatmap_polarity, axis=1)\n",
    "    ####  metrics for the val of the request\n",
    "    all_df['request_metric'] = all_df[(all_df['is_in_summary'] == 1) & (\n",
    "        all_df['is_sim'] == 1)]['nb_sentences'].sum() *100 /3000\n",
    "    summary_reconstructed = all_df.groupby('alias').agg({\n",
    "        'review_clean':\n",
    "        list,\n",
    "        'nb_sentences':\n",
    "        'mean',\n",
    "        'nb_review':\n",
    "        'mean',\n",
    "        'metric sim_ratio':\n",
    "        'mean',\n",
    "        'reviews_heatmaps_html':\n",
    "        list,\n",
    "        'reviews_heatmaps_polarity':\n",
    "        list\n",
    "    })\n",
    "\n",
    "    #print(\"check\")\n",
    "    #print(type(summary_reconstructed))\n",
    "    #print(summary_reconstructed.columns)\n",
    "    #print(summary_reconstructed.shape)\n",
    "    output_json = summary_reconstructed.to_dict()\n",
    "    return output_json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cdb0a77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
