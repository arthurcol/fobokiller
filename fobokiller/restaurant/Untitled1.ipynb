{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "9d302abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from selenium import webdriver\n",
    "import matplotlib.pyplot as plt\n",
    "import folium\n",
    "import time\n",
    "from selenium import webdriver\n",
    "import chromedriver_binary\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as ec\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from bs4 import BeautifulSoup\n",
    "from dotenv import load_dotenv, dotenv_values, find_dotenv\n",
    "from fobokiller.utils import subzones_paris\n",
    "from os.path import join,dirname\n",
    "import os\n",
    "import csv\n",
    "\n",
    "env_path = find_dotenv()\n",
    "#env_path = join(dirname(dirname(__file__)), '.env')\n",
    "load_dotenv(env_path)\n",
    "\n",
    "#api_key = dotenv_values()[\"YELP_KEY\"]\n",
    "\n",
    "api_key = os.getenv('YELP_KEY')\n",
    "\n",
    "def get_restaurants(centers, radius):\n",
    "    \"\"\"\n",
    "    Returns DataFrame of restaurants in Paris\n",
    "    \"\"\"\n",
    "    headers = {'Authorization': f'Bearer {api_key}'}\n",
    "    url = 'https://api.yelp.com/v3/businesses/search'\n",
    "\n",
    "    data = []\n",
    "\n",
    "    for i, c in enumerate(centers):\n",
    "        print(f'---------- Requesting API for subzone #{i+1} ----------')\n",
    "        for offset in range(0, 200, 50):\n",
    "            print(\n",
    "                f'   ------- Requesting API with offset = {offset} -------   ')\n",
    "            params = {\n",
    "                'limit': 50,\n",
    "                'categories': ['restaurants'],\n",
    "                'sort_by': 'review_count',\n",
    "                'offset': offset,\n",
    "                'latitude': c[0],\n",
    "                'longitude': c[1],\n",
    "                'radius': int(radius)\n",
    "            }\n",
    "\n",
    "            response = requests.get(url, headers=headers, params=params)\n",
    "            if response.status_code == 200:\n",
    "                data += response.json()['businesses']\n",
    "            elif response.status_code == 400:\n",
    "                print('400 Bad Request')\n",
    "                break\n",
    "\n",
    "    print(f'#####   Request completed, {len(data)} businesses fetched   ###')\n",
    "    return data\n",
    "\n",
    "\n",
    "### Create DF for Yelp data\n",
    "\n",
    "\n",
    "def create_df_yelp(data):\n",
    "\n",
    "    df = pd.DataFrame(columns=[\n",
    "        'alias', 'name', 'url', 'categories', 'latitude', 'longitude',\n",
    "        'address', 'zip_code', 'price', 'rating', 'review_count'\n",
    "    ])\n",
    "\n",
    "    features_to_loop = [\n",
    "        'alias', 'name', 'url', 'categories', 'price', 'rating', 'review_count'\n",
    "    ]\n",
    "\n",
    "    #populate DF\n",
    "    #if condition to avoid raising errors in case restaurant doesn't have all informations\n",
    "\n",
    "    for i, d in enumerate(data):\n",
    "\n",
    "        for f in features_to_loop:\n",
    "            if f in d:\n",
    "                df.loc[i, f] = d[f]\n",
    "            else:\n",
    "                df.loc[i, f] = ''\n",
    "\n",
    "        if 'location' in d:\n",
    "            if 'latitude' in d['coordinates']:\n",
    "                df.loc[i, 'latitude'] = d['coordinates']['latitude']\n",
    "            else:\n",
    "                df.loc[i, 'latitude'] = ''\n",
    "\n",
    "            if 'longitude' in d['coordinates']:\n",
    "                df.loc[i, 'longitude'] = d['coordinates']['longitude']\n",
    "            else:\n",
    "                df.loc[i, 'longitude'] = ''\n",
    "\n",
    "            if 'address1' in d['location']:\n",
    "                df.loc[i, 'address'] = d['location']['address1']\n",
    "            else:\n",
    "                df.loc[i, 'address'] = ''\n",
    "\n",
    "            if 'zip_code' in d['location']:\n",
    "                df.loc[i, 'zip_code'] = d['location']['zip_code']\n",
    "            else:\n",
    "                df.loc[i, 'zip_code'] = 0\n",
    "\n",
    "    #clean DF\n",
    "    #dtypes\n",
    "    df['latitude'] = df['latitude'].astype(float)\n",
    "    df['longitude'] = df['longitude'].astype(float)\n",
    "    df['zip_code'] = df['zip_code'].replace('', 0).astype(int)\n",
    "    df['rating'] = df['rating'].astype(float)\n",
    "    df['review_count'] = df['review_count'].astype(float)\n",
    "\n",
    "    #url\n",
    "    df['url'] = df['url'].apply(lambda txt: txt.split('?', 1)[0])\n",
    "\n",
    "    #price\n",
    "    prices = {'€': '1', '€€': '2', '€€€': '3', '€€€€': '4'}\n",
    "\n",
    "    for euro, num in prices.items():\n",
    "        df['price'] = df['price'].replace(euro, num)\n",
    "\n",
    "    df['price'] = df['price'].replace('', 0).astype(int)\n",
    "\n",
    "    #categories\n",
    "    df['categories'] = df['categories'].apply(\n",
    "        lambda dicts: ', '.join([d['alias'] for d in dicts]))\n",
    "\n",
    "    return df.drop_duplicates()\n",
    "\n",
    "\n",
    "\n",
    "def get_place_google_id(name,latitude,longitude):\n",
    "\n",
    "    url = 'https://maps.googleapis.com/maps/api/place/findplacefromtext/json'\n",
    "    params={\n",
    "        'key' :  os.getenv('GOOGLE_PLACE_KEY'),\n",
    "        'input' : name,\n",
    "        'inputtype' : 'textquery',\n",
    "        'locationbias' : f'point:{latitude},{longitude}'\n",
    "    }\n",
    "\n",
    "    response = requests.get(url,params=params)\n",
    "\n",
    "    #if conditions to avoid raising errors\n",
    "    if response.status_code != 200:\n",
    "        return ''\n",
    "\n",
    "    if 'candidates' in response.json():\n",
    "        response = response.json()['candidates']\n",
    "        if len(response)==0:\n",
    "            return ''\n",
    "        if 'place_id' in response[0]:\n",
    "            return response[0]['place_id']\n",
    "\n",
    "    return ''\n",
    "\n",
    "\n",
    "\n",
    "## Get place url\n",
    "\n",
    "\n",
    "def get_place_google_url(place_id):\n",
    "    url = 'https://maps.googleapis.com/maps/api/place/details/json'\n",
    "    params = {\n",
    "        'key': os.getenv('GOOGLE_PLACE_KEY'),\n",
    "        'place_id': place_id,\n",
    "        'fields': 'url'\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, params=params)\n",
    "\n",
    "    #if conditions to avoid raising errors\n",
    "    if response.status_code != 200:\n",
    "        return ''\n",
    "\n",
    "    if 'result' in response.json():\n",
    "        response = response.json()['result']\n",
    "        if 'url' in response:\n",
    "            return response['url']\n",
    "\n",
    "    return ''\n",
    "\n",
    "\n",
    "\n",
    "def get_reviews_google(url,scroll_limit=None,quiet_mode=True,return_count=False):\n",
    "    options=Options()\n",
    "    if quiet_mode:\n",
    "        options.add_argument('--headless')\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    driver.get(url)\n",
    "\n",
    "\n",
    "    ###Expand all the reviews using Selenium\n",
    "    # privacy pop-up\n",
    "    xpath = \"/html/body/c-wiz/div/div/div/div[2]/div[1]/div[4]/form/div[1]/div/button/span\"\n",
    "    driver.find_element_by_xpath(xpath).click()\n",
    "\n",
    "    #review_count click\n",
    "    xpath = '//*[@id=\"pane\"]/div/div[1]/div/div/div[2]/div[1]/div[1]/div[2]/div/div[1]/span[1]/span/span[1]/span[2]'\n",
    "\n",
    "    review_count = driver.find_element_by_xpath(xpath).text\n",
    "    review_count=review_count.split(' ', 1)[0]\n",
    "\n",
    "    driver.find_element_by_xpath(xpath).click()\n",
    "\n",
    "    # check\n",
    "    #driver.find_element_by_xpath(\"/html/body/div[3]/div[9]/div[8]/div/div[1]/div/div/div[38]/div/button/span/span\").click()\n",
    "\n",
    "    #scroll to show all reviews\n",
    "    time.sleep(2)\n",
    "    if scroll_limit:\n",
    "        review_count=scroll_limit\n",
    "    scrollable_div = driver.find_element_by_xpath('//*[@id=\"pane\"]/div/div[1]/div/div/div[2]')\n",
    "    for i in range(0,(round(int(review_count)/10-1))):\n",
    "        driver.execute_script('arguments[0].scrollTop = arguments[0].scrollHeight',\n",
    "                scrollable_div)\n",
    "        time.sleep(2)\n",
    "\n",
    "\n",
    "    ### Scrap the reviews info using BS\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "    #Scrap the reviews text\n",
    "    reviews_soup = soup.find_all('div', class_='ODSEW-ShBeI NIyLF-haAclf gm2-body-2')\n",
    "    reviews = [r.text for r in reviews_soup]\n",
    "\n",
    "    #Scrap the reviews rate\n",
    "    review_rates_soup = [s.find('span',class_='ODSEW-ShBeI-H1e3jb') for s in reviews_soup]\n",
    "    review_rates = [rr.attrs['aria-label'][1] for rr in review_rates_soup]\n",
    "    #Scrap the reviews date\n",
    "    review_dates_soup=[s.find('span', class_='ODSEW-ShBeI-RgZmSc-date') for s in reviews_soup]\n",
    "    review_dates=[rd.text for rd in review_dates_soup]\n",
    "\n",
    "\n",
    "    if return_count:\n",
    "\n",
    "        return review_count,review_dates,review_rates,reviews\n",
    "\n",
    "\n",
    "    return review_dates,review_rates,reviews\n",
    "\n",
    "### Get all reviews from a Google page\n",
    "\n",
    "\n",
    "def get_reviews_google(url,\n",
    "                       scroll_limit=None,\n",
    "                       quiet_mode=True,\n",
    "                       return_count=False):\n",
    "\n",
    "    # Import the webdriver\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_experimental_option('prefs',\n",
    "                                    {'intl.accept_languages': 'en,en_US'})\n",
    "\n",
    "    if quiet_mode:\n",
    "        options.add_argument('--headless')\n",
    "    driver = webdriver.Chrome(chrome_options=options)\n",
    "    driver.get(url)\n",
    "\n",
    "    # privacy pop-up\n",
    "\n",
    "    xpath = \"/html/body/c-wiz/div/div/div/div[2]/div[1]/div[4]/form/div[1]/div/button/span\"\n",
    "    driver.find_element_by_xpath(xpath).click()\n",
    "\n",
    "    #### expand the review\n",
    "\n",
    "    time.sleep(2)\n",
    "\n",
    "    class_ = \"ODSEW-KoToPc-ShBeI gXqMYb-hSRGPd\"\n",
    "\n",
    "    soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "\n",
    "    #total_number_of_reviews = soup.find(\"div\", class_=\"gm2-caption\").text\n",
    "    total_number_of_reviews = driver.find_element_by_xpath(\n",
    "        '//*[@id=\"pane\"]/div/div[1]/div/div/div[2]/div[1]/div[1]/div[2]/div/div[1]/span[1]/span/span[1]/span[2]'\n",
    "    ).text\n",
    "    total_number_of_reviews = total_number_of_reviews.split(' ', 1)[0]\n",
    "\n",
    "    ## Catch nombre d'avis\n",
    "    xpath = '//*[@id=\"pane\"]/div/div[1]/div/div/div[2]/div[1]/div[1]/div[2]/div/div[1]/span[1]/span/span[1]/span[2]'\n",
    "\n",
    "    review_count = driver.find_element_by_xpath(xpath).text\n",
    "    review_count = review_count.split(' ', 1)[0]\n",
    "\n",
    "    driver.find_element_by_xpath(\n",
    "        '//*[@id=\"pane\"]/div/div[1]/div/div/div[2]/div[1]/div[1]/div[2]/div/div[1]/span[1]/span/span[1]/span[2]'\n",
    "    ).click()\n",
    "    #total_number_of_reviews = soup.find(\"div\", class_=\"gm2-caption\").text\n",
    "    #a = total_number_of_reviews\n",
    "    time.sleep(1)\n",
    "    try :\n",
    "        xpatrier = \"/html/body/div[3]/div[9]/div[8]/div/div[1]/div/div/div[2]/div[7]/div[2]/button/span\"\n",
    "        driver.find_element_by_xpath(xpatrier).click()\n",
    "    except :\n",
    "        pass\n",
    "    time.sleep(2)\n",
    "    try :\n",
    "        xpatrecent = \"/html/body/div[3]/div[3]/div[1]/ul/li[2]\"\n",
    "        driver.find_element_by_xpath(xpatrecent).click()\n",
    "    except :\n",
    "        pass\n",
    "    ## Catch cellule of reviews\n",
    "\n",
    "    books_html = soup.findAll('div', class_=\"siAUzd-neVct\")\n",
    "    len(books_html)\n",
    "\n",
    "    #scroll to show all reviews\n",
    "    time.sleep(2)\n",
    "    if scroll_limit:\n",
    "        review_count = scroll_limit\n",
    "    scrollable_div = driver.find_element_by_xpath(\n",
    "        '//*[@id=\"pane\"]/div/div[1]/div/div/div[2]')\n",
    "    for i in range(0, (round(int(review_count) / 10 - 1))):\n",
    "        driver.execute_script(\n",
    "            'arguments[0].scrollTop = arguments[0].scrollHeight',\n",
    "            scrollable_div)\n",
    "        time.sleep(2)\n",
    "\n",
    "    #Find scroll layout\n",
    "    scrollable_div = driver.find_element_by_xpath(\n",
    "        '//*[@id=\"pane\"]/div/div[1]/div/div/div[2]')\n",
    "\n",
    "    print(review_count)\n",
    "    #Scroll as many times as necessary to load all reviews\n",
    "    for i in range(0, (round(int(review_count / 10 - 1)))):\n",
    "        driver.execute_script(\n",
    "            'arguments[0].scrollTop = arguments[0].scrollHeight',\n",
    "            scrollable_div)\n",
    "        time.sleep(2)\n",
    "    plus_list = driver.find_elements_by_link_text(\"Plus\")\n",
    "    for i in plus_list:\n",
    "        i.click()\n",
    "    response = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "    reviews = response.find_all('div',\n",
    "                                class_='ODSEW-ShBeI NIyLF-haAclf gm2-body-2')\n",
    "\n",
    "    return reviews\n",
    "\n",
    "\n",
    "def get_review_summary(result_set):\n",
    "    rev_dict = {'Review Rate': [], 'Review Time': [], 'Review Text': []}\n",
    "    for result in result_set:\n",
    "\n",
    "        review_rate = result.find('span',\n",
    "                                  class_='ODSEW-ShBeI-H1e3jb')[\"aria-label\"]\n",
    "        review_time = result.find('span',\n",
    "                                  class_='ODSEW-ShBeI-RgZmSc-date').text\n",
    "        review_text = result.find('span', class_='ODSEW-ShBeI-text').text\n",
    "        rev_dict['Review Rate'].append(review_rate)\n",
    "        rev_dict['Review Time'].append(review_time)\n",
    "        rev_dict['Review Text'].append(review_text)\n",
    "    A = pd.DataFrame(rev_dict)\n",
    "\n",
    "    A[\"Review Rate\"] = [i.split(\"\\xa0\")[0] for i in A[\"Review Rate\"]]\n",
    "    A[\"Review Time\"] = [i.strip(\"il y a \") for i in A[\"Review Time\"]]\n",
    "    A[\"Review Time\"] = [i.replace(\"une\", \"1\") for i in A[\"Review Time\"]]\n",
    "    A[\"Review Time\"] = [i.replace(\"un\", \"1\") for i in A[\"Review Time\"]]\n",
    "    return A\n",
    "\n",
    "\n",
    "def get_all_gr(url, iid, name, alias):\n",
    "    name\n",
    "    os.path.exists(name.replace(\" \", \"_\").replace(\"'\", \"\") + \".csv\")\n",
    "    if os.path.exists(name.replace(\" \", \"_\").replace(\"'\", \"\") + \".csv\") :\n",
    "        test = get_reviews_google(url, scroll_limit=10, quiet_mode=False)\n",
    "        table = get_review_summary(test)\n",
    "        table[\"id\"] = iid\n",
    "        table[\"name\"] = name\n",
    "        table[\"alias\"] = alias\n",
    "        table.to_csv(name.replace(\" \", \"_\").replace(\"'\", \"\") + \".csv\")\n",
    "        os.system(\"\"\"gsutil cp '*.csv' 'gs://wagon-data-722-manoharan/restaurant/'\"\"\")\n",
    "    else :\n",
    "        test = get_reviews_google(url, scroll_limit=10, quiet_mode=False)\n",
    "        table = get_review_summary(test)\n",
    "        table[\"id\"] = iid\n",
    "        table[\"name\"] = name\n",
    "        table[\"alias\"] = alias\n",
    "        table.to_csv(name.replace(\" \", \"_\").replace(\"'\", \"\") + \".csv\")\n",
    "        os.system(\"\"\"gsutil cp '*.csv' 'gs://wagon-data-722-manoharan/restaurant/'\"\"\")\n",
    "    return True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "4d065d28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DockerFile       \u001b[1m\u001b[36mfobokiller\u001b[m\u001b[m       \u001b[1m\u001b[36mnicolasmanoharan\u001b[m\u001b[m\r\n",
      "\u001b[1m\u001b[36mdemo\u001b[m\u001b[m             \u001b[1m\u001b[36mkaggle_credits\u001b[m\u001b[m\r\n"
     ]
    }
   ],
   "source": [
    "!ls .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "b3d37f7f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"fobokiller/data/restaurant_google.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800e3f0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9079e07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "7e5533a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s6/nxj_k6112bj7cnd89_8b9l0c0000gn/T/ipykernel_24950/3032727061.py:262: DeprecationWarning: use options instead of chrome_options\n",
      "  driver = webdriver.Chrome(chrome_options=options)\n",
      "/var/folders/s6/nxj_k6112bj7cnd89_8b9l0c0000gn/T/ipykernel_24950/3032727061.py:268: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  driver.find_element_by_xpath(xpath).click()\n"
     ]
    },
    {
     "ename": "NoSuchWindowException",
     "evalue": "Message: no such window: window was already closed\n  (Session info: chrome=96.0.4664.55)\nStacktrace:\n0   chromedriver                        0x000000010af18269 __gxx_personality_v0 + 582729\n1   chromedriver                        0x000000010aea3c33 __gxx_personality_v0 + 106003\n2   chromedriver                        0x000000010aa60e28 chromedriver + 171560\n3   chromedriver                        0x000000010aa50a95 chromedriver + 105109\n4   chromedriver                        0x000000010aa51f42 chromedriver + 110402\n5   chromedriver                        0x000000010aa4ac22 chromedriver + 80930\n6   chromedriver                        0x000000010aa622b3 chromedriver + 176819\n7   chromedriver                        0x000000010aac5b0c chromedriver + 584460\n8   chromedriver                        0x000000010aab3c23 chromedriver + 511011\n9   chromedriver                        0x000000010aa8975e chromedriver + 337758\n10  chromedriver                        0x000000010aa8aa95 chromedriver + 342677\n11  chromedriver                        0x000000010aed48ab __gxx_personality_v0 + 305803\n12  chromedriver                        0x000000010aeeb863 __gxx_personality_v0 + 399939\n13  chromedriver                        0x000000010aef0c7f __gxx_personality_v0 + 421471\n14  chromedriver                        0x000000010aeecbba __gxx_personality_v0 + 404890\n15  chromedriver                        0x000000010aec8e51 __gxx_personality_v0 + 258097\n16  chromedriver                        0x000000010af08158 __gxx_personality_v0 + 516920\n17  chromedriver                        0x000000010af082e1 __gxx_personality_v0 + 517313\n18  chromedriver                        0x000000010af1f6f8 __gxx_personality_v0 + 612568\n19  libsystem_pthread.dylib             0x00007fff2039c8fc _pthread_start + 224\n20  libsystem_pthread.dylib             0x00007fff20398443 thread_start + 15\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNoSuchWindowException\u001b[0m                     Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/s6/nxj_k6112bj7cnd89_8b9l0c0000gn/T/ipykernel_24950/4036856869.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mget_all_gr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"lien\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"name\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"alias\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/s6/nxj_k6112bj7cnd89_8b9l0c0000gn/T/ipykernel_24950/3032727061.py\u001b[0m in \u001b[0;36mget_all_gr\u001b[0;34m(url, iid, name, alias)\u001b[0m\n\u001b[1;32m    369\u001b[0m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"'\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"'\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".csv\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 371\u001b[0;31m         \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_reviews_google\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscroll_limit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquiet_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    372\u001b[0m         \u001b[0mtable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_review_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m         \u001b[0mtable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"id\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/s6/nxj_k6112bj7cnd89_8b9l0c0000gn/T/ipykernel_24950/3032727061.py\u001b[0m in \u001b[0;36mget_reviews_google\u001b[0;34m(url, scroll_limit, quiet_mode, return_count)\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[0mclass_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"ODSEW-KoToPc-ShBeI gXqMYb-hSRGPd\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m     \u001b[0msoup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage_source\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"html.parser\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m     \u001b[0;31m#total_number_of_reviews = soup.find(\"div\", class_=\"gm2-caption\").text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/FOBO/lib/python3.8/site-packages/selenium/webdriver/remote/webdriver.py\u001b[0m in \u001b[0;36mpage_source\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    918\u001b[0m                 \u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage_source\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m         \"\"\"\n\u001b[0;32m--> 920\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCommand\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGET_PAGE_SOURCE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'value'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    921\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/FOBO/lib/python3.8/site-packages/selenium/webdriver/remote/webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, driver_command, params)\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 418\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    419\u001b[0m             response['value'] = self._unwrap_value(\n\u001b[1;32m    420\u001b[0m                 response.get('value', None))\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/FOBO/lib/python3.8/site-packages/selenium/webdriver/remote/errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[0;34m(self, response)\u001b[0m\n\u001b[1;32m    241\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'alert'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_value_or_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mMapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_KT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_VT\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_KT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_VT\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0m_VT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNoSuchWindowException\u001b[0m: Message: no such window: window was already closed\n  (Session info: chrome=96.0.4664.55)\nStacktrace:\n0   chromedriver                        0x000000010af18269 __gxx_personality_v0 + 582729\n1   chromedriver                        0x000000010aea3c33 __gxx_personality_v0 + 106003\n2   chromedriver                        0x000000010aa60e28 chromedriver + 171560\n3   chromedriver                        0x000000010aa50a95 chromedriver + 105109\n4   chromedriver                        0x000000010aa51f42 chromedriver + 110402\n5   chromedriver                        0x000000010aa4ac22 chromedriver + 80930\n6   chromedriver                        0x000000010aa622b3 chromedriver + 176819\n7   chromedriver                        0x000000010aac5b0c chromedriver + 584460\n8   chromedriver                        0x000000010aab3c23 chromedriver + 511011\n9   chromedriver                        0x000000010aa8975e chromedriver + 337758\n10  chromedriver                        0x000000010aa8aa95 chromedriver + 342677\n11  chromedriver                        0x000000010aed48ab __gxx_personality_v0 + 305803\n12  chromedriver                        0x000000010aeeb863 __gxx_personality_v0 + 399939\n13  chromedriver                        0x000000010aef0c7f __gxx_personality_v0 + 421471\n14  chromedriver                        0x000000010aeecbba __gxx_personality_v0 + 404890\n15  chromedriver                        0x000000010aec8e51 __gxx_personality_v0 + 258097\n16  chromedriver                        0x000000010af08158 __gxx_personality_v0 + 516920\n17  chromedriver                        0x000000010af082e1 __gxx_personality_v0 + 517313\n18  chromedriver                        0x000000010af1f6f8 __gxx_personality_v0 + 612568\n19  libsystem_pthread.dylib             0x00007fff2039c8fc _pthread_start + 224\n20  libsystem_pthread.dylib             0x00007fff20398443 thread_start + 15\n"
     ]
    }
   ],
   "source": [
    "i = 2\n",
    "get_all_gr(df[\"lien\"][i],df[\"id\"][i],df[\"name\"][i],df[\"alias\"][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "7f23a811",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s6/nxj_k6112bj7cnd89_8b9l0c0000gn/T/ipykernel_24950/2736436677.py:14: DeprecationWarning: use options instead of chrome_options\n",
      "  driver = webdriver.Chrome(chrome_options=options)\n",
      "/var/folders/s6/nxj_k6112bj7cnd89_8b9l0c0000gn/T/ipykernel_24950/2736436677.py:19: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  driver.find_element_by_xpath(xpath).click()\n",
      "/var/folders/s6/nxj_k6112bj7cnd89_8b9l0c0000gn/T/ipykernel_24950/2736436677.py:30: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  total_number_of_reviews = driver.find_element_by_xpath('//*[@id=\"pane\"]/div/div[1]/div/div/div[2]/div[1]/div[1]/div[2]/div/div[1]/span[1]/span/span[1]/span[2]').text\n",
      "/var/folders/s6/nxj_k6112bj7cnd89_8b9l0c0000gn/T/ipykernel_24950/2736436677.py:36: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  review_count = driver.find_element_by_xpath(xpath).text\n",
      "/var/folders/s6/nxj_k6112bj7cnd89_8b9l0c0000gn/T/ipykernel_24950/2736436677.py:39: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  driver.find_element_by_xpath('//*[@id=\"pane\"]/div/div[1]/div/div/div[2]/div[1]/div[1]/div[2]/div/div[1]/span[1]/span/span[1]/span[2]'\n",
      "/var/folders/s6/nxj_k6112bj7cnd89_8b9l0c0000gn/T/ipykernel_24950/2736436677.py:46: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  driver.find_element_by_xpath(xpatrier).click()\n",
      "/var/folders/s6/nxj_k6112bj7cnd89_8b9l0c0000gn/T/ipykernel_24950/2736436677.py:52: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  driver.find_element_by_xpath(xpatrecent).click()\n",
      "/var/folders/s6/nxj_k6112bj7cnd89_8b9l0c0000gn/T/ipykernel_24950/2736436677.py:56: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  test = driver.find_elements_by_link_text(\"Plus\")\n",
      "/var/folders/s6/nxj_k6112bj7cnd89_8b9l0c0000gn/T/ipykernel_24950/2736436677.py:64: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  scrollable_div = driver.find_element_by_xpath('//*[@id=\"pane\"]/div/div[1]/div/div/div[2]')\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "int() argument must be a string, a bytes-like object or a number, not 'tuple'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/s6/nxj_k6112bj7cnd89_8b9l0c0000gn/T/ipykernel_24950/2736436677.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0mreview_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscroll_limit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0mscrollable_div\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_element_by_xpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'//*[@id=\"pane\"]/div/div[1]/div/div/div[2]'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreview_count\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m     \u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute_script\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'arguments[0].scrollTop = arguments[0].scrollHeight'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscrollable_div\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: int() argument must be a string, a bytes-like object or a number, not 'tuple'"
     ]
    }
   ],
   "source": [
    "url=df[\"lien\"][i]\n",
    "scroll_limit=None,\n",
    "quiet_mode=False,\n",
    "return_count=False\n",
    "\n",
    "# Import the webdriver\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_experimental_option('prefs',\n",
    "                                    {'intl.accept_languages': 'en,en_US'})\n",
    "\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_experimental_option('prefs', {'intl.accept_languages': 'en,en_US'})\n",
    "driver = webdriver.Chrome(chrome_options=options)\n",
    "driver.get(url)\n",
    "\n",
    "    # privacy pop-up\n",
    "xpath = \"/html/body/c-wiz/div/div/div/div[2]/div[1]/div[4]/form/div[1]/div/button/span\"\n",
    "driver.find_element_by_xpath(xpath).click()\n",
    "\n",
    "    #### expand the review\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "class_ = \"ODSEW-KoToPc-ShBeI gXqMYb-hSRGPd\"\n",
    "\n",
    "soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "\n",
    "    #total_number_of_reviews = soup.find(\"div\", class_=\"gm2-caption\").text\n",
    "total_number_of_reviews = driver.find_element_by_xpath('//*[@id=\"pane\"]/div/div[1]/div/div/div[2]/div[1]/div[1]/div[2]/div/div[1]/span[1]/span/span[1]/span[2]').text\n",
    "total_number_of_reviews = total_number_of_reviews.split(' ', 1)[0]\n",
    "\n",
    "    ## Catch nombre d'avis\n",
    "xpath = '//*[@id=\"pane\"]/div/div[1]/div/div/div[2]/div[1]/div[1]/div[2]/div/div[1]/span[1]/span/span[1]/span[2]'\n",
    "\n",
    "review_count = driver.find_element_by_xpath(xpath).text\n",
    "review_count = review_count.split(' ', 1)[0]\n",
    "\n",
    "driver.find_element_by_xpath('//*[@id=\"pane\"]/div/div[1]/div/div/div[2]/div[1]/div[1]/div[2]/div/div[1]/span[1]/span/span[1]/span[2]'\n",
    ").click()\n",
    "    #total_number_of_reviews = soup.find(\"div\", class_=\"gm2-caption\").text\n",
    "    #a = total_number_of_reviews\n",
    "time.sleep(1)\n",
    "try :\n",
    "    xpatrier = \"/html/body/div[3]/div[9]/div[8]/div/div[1]/div/div/div[2]/div[7]/div[2]/button/span\"\n",
    "    driver.find_element_by_xpath(xpatrier).click()\n",
    "except :\n",
    "    pass\n",
    "time.sleep(2)\n",
    "try :\n",
    "        xpatrecent = \"/html/body/div[3]/div[3]/div[1]/ul/li[2]\"\n",
    "        driver.find_element_by_xpath(xpatrecent).click()\n",
    "except :\n",
    "    pass\n",
    "    ## Catch cellule of reviews\n",
    "test = driver.find_elements_by_link_text(\"Plus\")\n",
    "books_html = soup.findAll('div', class_=\"siAUzd-neVct\")\n",
    "len(books_html)\n",
    "\n",
    "    #scroll to show all reviews\n",
    "time.sleep(2)\n",
    "if scroll_limit:\n",
    "    review_count = scroll_limit\n",
    "scrollable_div = driver.find_element_by_xpath('//*[@id=\"pane\"]/div/div[1]/div/div/div[2]')\n",
    "for i in range(0, (round(int(review_count) / 10 - 1))):\n",
    "    driver.execute_script('arguments[0].scrollTop = arguments[0].scrollHeight',scrollable_div)\n",
    "    time.sleep(2)\n",
    "\n",
    "    #Find scroll layout\n",
    "scrollable_div = driver.find_element_by_xpath('//*[@id=\"pane\"]/div/div[1]/div/div/div[2]')\n",
    "\n",
    "print(review_count)\n",
    "    #Scroll as many times as necessary to load all reviews\n",
    "for i in range(0, (round(int(review_count / 10 - 1)))):\n",
    "    driver.execute_script('arguments[0].scrollTop = arguments[0].scrollHeight',scrollable_div)\n",
    "    time.sleep(2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "607d9d6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s6/nxj_k6112bj7cnd89_8b9l0c0000gn/T/ipykernel_24950/2624411924.py:14: DeprecationWarning: use options instead of chrome_options\n",
      "  driver = webdriver.Chrome(chrome_options=options)\n"
     ]
    }
   ],
   "source": [
    "url=df[\"lien\"][i]\n",
    "scroll_limit=None,\n",
    "quiet_mode=False,\n",
    "return_count=False\n",
    "\n",
    "# Import the webdriver\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_experimental_option('prefs',\n",
    "                                    {'intl.accept_languages': 'en,en_US'})\n",
    "\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_experimental_option('prefs', {'intl.accept_languages': 'en,en_US'})\n",
    "driver = webdriver.Chrome(chrome_options=options)\n",
    "driver.get(url)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9ebce67c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.chrome.webdriver.WebDriver (session=\"e8a722929147691341a515a22045c1fe\")>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "439ca93f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'review' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/s6/nxj_k6112bj7cnd89_8b9l0c0000gn/T/ipykernel_24950/2949792035.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmore_button\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'{review}//a[.=\"(more)\"]'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'review' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "264a0ab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s6/nxj_k6112bj7cnd89_8b9l0c0000gn/T/ipykernel_24950/3654066841.py:1: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  plus_list = driver.find_elements_by_link_text(\"Plus\")\n"
     ]
    }
   ],
   "source": [
    "plus_list = driver.find_elements_by_link_text(\"Plus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4ea4331d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plus_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f7fb3301",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (755780088.py, line 9)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/var/folders/s6/nxj_k6112bj7cnd89_8b9l0c0000gn/T/ipykernel_24950/755780088.py\"\u001b[0;36m, line \u001b[0;32m9\u001b[0m\n\u001b[0;31m    return reviews\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "plus_list = driver.find_elements_by_link_text(\"Plus\")\n",
    "for i in plus_list:\n",
    "    i.click()\n",
    "response = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "reviews = response.find_all('div',\n",
    "                                class_='ODSEW-ShBeI NIyLF-haAclf gm2-body-2')\n",
    "\n",
    " return reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067308fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_review_summary(result_set):\n",
    "    rev_dict = {'Review Rate': [], 'Review Time': [], 'Review Text': []}\n",
    "    for result in result_set:\n",
    "\n",
    "        review_rate = result.find('span',\n",
    "                                  class_='ODSEW-ShBeI-H1e3jb')[\"aria-label\"]\n",
    "        review_time = result.find('span',\n",
    "                                  class_='ODSEW-ShBeI-RgZmSc-date').text\n",
    "        review_text = result.find('span', class_='ODSEW-ShBeI-text').text\n",
    "        rev_dict['Review Rate'].append(review_rate)\n",
    "        rev_dict['Review Time'].append(review_time)\n",
    "        rev_dict['Review Text'].append(review_text)\n",
    "    A = pd.DataFrame(rev_dict)\n",
    "\n",
    "    A[\"Review Rate\"] = [i.split(\"\\xa0\")[0] for i in A[\"Review Rate\"]]\n",
    "    A[\"Review Time\"] = [i.strip(\"il y a \") for i in A[\"Review Time\"]]\n",
    "    A[\"Review Time\"] = [i.replace(\"une\", \"1\") for i in A[\"Review Time\"]]\n",
    "    A[\"Review Time\"] = [i.replace(\"un\", \"1\") for i in A[\"Review Time\"]]\n",
    "    return A"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
